{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) Microsoft Corporation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Mask RCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook will train the model through Azure ML Compute.\n",
    "\n",
    "In this notebook you will\n",
    "* Examine the training pipeline configuration\n",
    "* Create or connect to a GPU-enabled Azure ML Compute target.\n",
    "* Examine the trainng and model export scripts.\n",
    "* Create an Azure ML Estimator for training.\n",
    "* Submit the experiment for training.\n",
    "* Download and register the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the pipeline configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " !cat ./trainingcode/stockout_pipeline.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import shutil\n",
    "import azureml\n",
    "\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "script_folder = './trainingcode'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "\n",
    "exp = Experiment(workspace=ws, name='voiddetection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Azure ML Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name = \"gpuclusternc\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n",
    "                                                           max_nodes=1)\n",
    "\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the training and model export scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./trainingcode/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--pipeline-config-path', type=str, dest='pipeline_config', help='Inception pipeline config path')\n",
    "parser.add_argument('--num-steps', type=int, dest='num_steps', help='number of training steps')\n",
    "args=parser.parse_args()\n",
    "\n",
    "def install(package):\n",
    "    subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "    \n",
    "install('/datastore/packages/object_detection-0.1.tar.gz')\n",
    "install('/datastore/packages/slim-0.1.tar.gz')\n",
    "install('/datastore/packages/pycocotools-2.0.tar.gz')\n",
    "\n",
    "from tensorflow.python.platform import flags\n",
    "from object_detection import model_main\n",
    "\n",
    "class TrainFlagValues:\n",
    "    pipeline_config_path=args.pipeline_config\n",
    "    model_dir='./outputs'\n",
    "    num_train_steps=args.num_steps\n",
    "    sample_1_of_n_eval_examples=10\n",
    "    sample_1_of_n_eval_on_train_examples=5\n",
    "    alsologtostderr=True\n",
    "    hparams_overrides=None\n",
    "    checkpoint_dir=None\n",
    "    run_once=False\n",
    "    log_dir=\"./logs\"\n",
    "    \n",
    "model_main.FLAGS = TrainFlagValues()\n",
    "\n",
    "model_main.main(None)\n",
    "\n",
    "subprocess.check_output([list({sys.executable})[0],'./export.py','--pipeline-config-path',args.pipeline_config,'--num-steps',str(args.num_steps)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./trainingcode/export.py\n",
    "from object_detection import export_inference_graph\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--pipeline-config-path', type=str, dest='pipeline_config', help='Inception pipeline config path')\n",
    "parser.add_argument('--num-steps', type=int, dest='num_steps', help='number of training steps')\n",
    "args=parser.parse_args()\n",
    "\n",
    "class ExportFlagValues:\n",
    "    pipeline_config_path=args.pipeline_config\n",
    "    input_type=\"image_tensor\"\n",
    "    input_shape=None\n",
    "    trained_checkpoint_prefix=\"./outputs/model.ckpt-\"+str(args.num_steps)\n",
    "    output_directory=\"./outputs/frozen_graph/\"\n",
    "    config_override=''\n",
    "    write_inference_graph=False\n",
    "    \n",
    "export_inference_graph.FLAGS=ExportFlagValues()\n",
    "\n",
    "export_inference_graph.main(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "script_params = {\n",
    "    \"--pipeline-config-path\":\"./stockout_pipeline.config\",\n",
    "    \"--num-steps\":50000\n",
    "}\n",
    "\n",
    "est = TensorFlow(source_directory='trainingcode',\n",
    "                compute_target=compute_target,\n",
    "                script_params=script_params,\n",
    "                entry_script='train.py',\n",
    "                inputs=[ds.as_download(\"/datastore\")],\n",
    "                use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-14 13:39:44.166052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-08-14 13:39:44.166116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-08-14 13:39:44.166125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-08-14 13:39:44.166131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-08-14 13:39:44.166308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 91c9:00:00.0, compute capability: 3.7)\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.29s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.937\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.423\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.501\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.552\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.436\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.558\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.576\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.617\n"
     ]
    }
   ],
   "source": [
    "run = exp.submit(est)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run.register_model(model_name='maskrcnn-void-detection', model_path='outputs/frozen_graph/frozen_inference_graph.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model folder in the current directory\n",
    "os.makedirs('./model', exist_ok=True)\n",
    "\n",
    "for f in run.get_file_names():\n",
    "    if f.startswith('outputs/frozen_graph/frozen'):\n",
    "        output_file_path = os.path.join('./model', f.split('/')[-1])\n",
    "        print('Downloading from {} to {} ...'.format(f, output_file_path))\n",
    "        run.download_file(name=f, output_file_path=output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
