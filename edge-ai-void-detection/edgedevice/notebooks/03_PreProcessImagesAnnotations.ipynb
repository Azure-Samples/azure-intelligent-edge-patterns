{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) Microsoft Corporation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing of Images for TF OD API  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook will get the data ready for training.\n",
    "\n",
    "In this notebook you will\n",
    "* Tranform the test data set into TensorFlow records.\n",
    "* Add the TensorFlow records to the datastore.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we create tensorflow records for training and validation datasets, details can be found [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import io\n",
    "import glob\n",
    "from PIL import Image\n",
    "import random\n",
    "from lxml import etree\n",
    "import contextlib2\n",
    "import azureml\n",
    "\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "from IPython.display import display\n",
    "from utilities import create_dir\n",
    "random.seed(4)\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.dataset_tools import tf_record_creation_util\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotated Images directory\n",
    "data_dir = './dataset'\n",
    "\n",
    "# Label map path\n",
    "label_map_path = './outofstock_label_map.pbtxt'\n",
    "\n",
    "# Outputs path\n",
    "output_dir = 'tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read label dictionary\n",
    "label_map_dict = label_map_util.get_label_map_dict(label_map_path)\n",
    "class_name = 'outofstock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow record output paths\n",
    "train_output_path = os.path.join(output_dir, 'outofstock_train.record')\n",
    "val_output_path = os.path.join(output_dir, 'outofstock_val.record')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets the total number of images for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_images = glob.glob(data_dir + '/**/'+ '*.jpg')\n",
    "print(\"There are {} images.\".format(len(in_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets the number of images in the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images =  glob.glob(data_dir + '/test/'+ '*.jpg')\n",
    "print(\"There are {} images.\".format(len(val_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets the number of images in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images =  glob.glob(data_dir + '/train/'+ '*.jpg')\n",
    "print(\"There are {} images.\".format(len(train_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample of training images\n",
    "for img_path in train_images[:5]:\n",
    "    img = Image.open(img_path)\n",
    "    display(img)\n",
    "    print(img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample of validation images\n",
    "for img_path in val_images[:5]:\n",
    "    img = Image.open(img_path)\n",
    "    display(img)\n",
    "    print(img.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes the XML annotation and image into a format TensorFlow can handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_tf_example(data, label_map_dict, img_path):\n",
    "    with tf.Graph().as_default():\n",
    "        image_contents = tf.read_file(img_path)\n",
    "        image = tf.image.decode_jpeg(image_contents, channels=3)\n",
    "        init_op = tf.initialize_all_tables()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_op)\n",
    "            try:\n",
    "                tmp = sess.run(image)\n",
    "            except InvalidArgumentError:\n",
    "                print(img_path)\n",
    "    with tf.gfile.GFile(img_path, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    if image.format != 'JPEG':\n",
    "        raise ValueError('Image format not JPEG')\n",
    "    width = int(data['size']['width'])\n",
    "    height = int(data['size']['height'])\n",
    "    xmins = []\n",
    "    ymins = []\n",
    "    xmaxs = []\n",
    "    ymaxs = []\n",
    "    classes = []\n",
    "    classes_text = []\n",
    "\n",
    "    if 'object' in data:\n",
    "        for obj in data['object']:\n",
    "            xmin = float(obj['bndbox']['xmin'])\n",
    "            xmax = float(obj['bndbox']['xmax'])\n",
    "            ymin = float(obj['bndbox']['ymin'])\n",
    "            ymax = float(obj['bndbox']['ymax'])\n",
    "\n",
    "            xmins.append(xmin / width)\n",
    "            ymins.append(ymin / height)\n",
    "            xmaxs.append(xmax / width)\n",
    "            ymaxs.append(ymax / height)\n",
    "            classes_text.append(class_name.encode('utf8'))\n",
    "            classes.append(label_map_dict[class_name])   \n",
    "    feature_dict = {\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(data['filename'].encode('utf8')),\n",
    "        'image/source_id': dataset_util.bytes_feature(data['filename'].encode('utf8')),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes)\n",
    "    }\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the actual TensorFlow records for the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_record(output_filename, num_shards, label_map_dict, examples):\n",
    "    with contextlib2.ExitStack() as tf_record_close_stack:\n",
    "        output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(tf_record_close_stack, output_filename, num_shards)\n",
    "        for idx, example in enumerate(examples):\n",
    "            if idx % 50 == 0:\n",
    "                print('On image {} of {}'.format(idx, len(examples)))\n",
    "            xml_path = os.path.join(example[:-4] + '.xml')\n",
    "            if not os.path.exists(xml_path):\n",
    "                print('Could not find {}, ignoring example'.format(xml_path))\n",
    "                continue\n",
    "            with tf.gfile.GFile(xml_path, 'r') as fid:\n",
    "                xml_str = fid.read()\n",
    "            xml = etree.fromstring(xml_str)\n",
    "            data = dataset_util.recursive_parse_xml_to_dict(xml)['annotation']\n",
    "            try:\n",
    "                tf_example = dict_to_tf_example(data, label_map_dict, example)\n",
    "                if tf_example:\n",
    "                    shard_idx = idx % num_shards\n",
    "                    output_tfrecords[shard_idx].write(tf_example.SerializeToString())\n",
    "            except ValueError:\n",
    "                print('Invalid example: {}, ignoring.'.format(xml_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensorflow records for training\n",
    "create_tf_record(train_output_path, 2, label_map_dict, train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # Create tensorflow records for validation\n",
    "create_tf_record(val_output_path, 1, label_map_dict, val_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds the TensorFlow records to the datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "\n",
    "ds.upload(src_dir=output_dir, target_path='./tfdataset',\n",
    "          overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can move to training the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
