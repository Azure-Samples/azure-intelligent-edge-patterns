{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VPU based inferencing and deployment on IoT Edge device using Azure Machine Learning \n",
    "\n",
    "We will do deployment similar to the original: https://github.com/Azure-Samples/onnxruntime-iot-edge/tree/master/AzureML-OpenVINO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![End-to-end pipeline with ONNX Runtime](https://github.com/manashgoswami/byoc/raw/master/ONNXRuntime-AML.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azureml-core azureml-contrib-iot azure-mgmt-containerregistry azure-cli\n",
    "!az extension add --name azure-cli-iot-ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core as azcore\n",
    "\n",
    "print(\"SDK version:\", azcore.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup the Azure Machine Learning Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a AML Workspace : using existing config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Workspace \n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 AML Workspace : create a new workspace"
   ]
  },
  {
   "source": [
    "Alternatively, you could create a workspace using `azureml.core`:\n",
    "\n",
    "```\n",
    "#Initialize Workspace \n",
    "from azureml.core import Workspace\n",
    "\n",
    "### Change this cell from markdown to code and run this if you need to create a workspace \n",
    "### Update the values for your workspace below\n",
    "ws=Workspace.create(subscription_id=\"<subscription-id goes here>\",\n",
    "                resource_group=\"<resource group goes here>\",\n",
    "                name=\"<name of the AML workspace>\",\n",
    "                location=\"<location>\")\n",
    "                \n",
    "ws.write_config()\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 AML Workspace : initialize an existing workspace\n",
    "Download the `config.json` file for your AML Workspace from the Azure portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Workspace \n",
    "from azureml.core import Workspace\n",
    "\n",
    "## existing AML Workspace in config.json\n",
    "ws = Workspace.from_config('config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup the trained model to use in this example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Register the trained model in workspace from the ONNX Model Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "onnx_model_url = \"https://onnxzoo.blob.core.windows.net/models/opset_8/tiny_yolov2/tiny_yolov2.tar.gz\"\n",
    "urllib.request.urlretrieve(onnx_model_url, filename=\"tiny_yolov2.tar.gz\")\n",
    "!tar xvzf tiny_yolov2.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(workspace = ws, \n",
    "                       model_path = \"./tiny_yolov2/Model.onnx\",\n",
    "                       model_name = \"Model.onnx\",\n",
    "                       tags = {\"data\": \"Imagenet\", \"model\": \"object_detection\", \"type\": \"TinyYolo\"},\n",
    "                       description = \"real-time object detection model from ONNX model zoo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load the model from your workspace model registry\n",
    "For e.g. this could be the ONNX model exported from your training experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "model = Model(name='Model.onnx', workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the application container image\n",
    "This container is the IoT Edge module that will be deployed on the UP<sup>2</sup> device. \n",
    "    1. This container is using a pre-build base image for ONNX Runtime.\n",
    "    2. Includes a `score.py` script, Must include a `run()` and `init()` function. The `init()` is entrypoint that reads the camera frames from /device/video0. The `run()` function is a dummy module to satisfy AML-sdk checks.\n",
    "    3. `amlpackage_inference.py` script which is used to process the input frame and run the inference session and\n",
    "    4. the ONNX model, label file used by the ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "# Licensed under the MIT license. See LICENSE file in the project root for\n",
    "# full license information.\n",
    "\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import io\n",
    "import csv\n",
    "\n",
    "\n",
    "# Imports for inferencing\n",
    "import onnxruntime as rt\n",
    "from amlpackage_inference import run_onnx\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Imports for communication w/IOT Hub\n",
    "from iothub_client import IoTHubModuleClient, IoTHubClientError, IoTHubTransportProvider\n",
    "from iothub_client import IoTHubMessage, IoTHubMessageDispositionResult, IoTHubError\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Imports for the http server\n",
    "from flask import Flask, request\n",
    "import json\n",
    "\n",
    "# Imports for storage\n",
    "import os\n",
    "# from azure.storage.blob import BlockBlobService, PublicAccess, AppendBlobService\n",
    "import random\n",
    "import string\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from pytz import timezone  \n",
    "import time\n",
    "import json\n",
    "\n",
    "class HubManager(object):\n",
    "    def __init__(\n",
    "            self,\n",
    "            protocol=IoTHubTransportProvider.MQTT):\n",
    "        self.client_protocol = protocol\n",
    "        self.client = IoTHubModuleClient()\n",
    "        self.client.create_from_environment(protocol)\n",
    "\n",
    "        # set the time until a message times out\n",
    "        self.client.set_option(\"messageTimeout\", MESSAGE_TIMEOUT)\n",
    "\n",
    "    # Forwards the message received onto the next stage in the process.\n",
    "    def forward_event_to_output(self, outputQueueName, event, send_context):\n",
    "        self.client.send_event_async(\n",
    "            outputQueueName, event, send_confirmation_callback, send_context)\n",
    "\n",
    "\n",
    "\n",
    "def send_confirmation_callback(message, result, user_context):\n",
    "    \"\"\"\n",
    "    Callback received when the message that we're forwarding is processed.\n",
    "    \"\"\"\n",
    "    print(\"Confirmation[%d] received for message with result = %s\" % (user_context, result))\n",
    "\n",
    "\n",
    "def get_tinyyolo_frame_from_encode(msg):\n",
    "    \"\"\"\n",
    "    Formats jpeg encoded msg to frame that can be processed by tiny_yolov2\n",
    "    \"\"\"\n",
    "    #inp = np.array(msg).reshape((len(msg),1))\n",
    "    #frame = cv2.imdecode(inp.astype(np.uint8), 1)\n",
    "    frame = cv2.cvtColor(msg, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # resize and pad to keep input frame aspect ratio\n",
    "    h, w = frame.shape[:2]\n",
    "    tw = 416 if w > h else int(np.round(416.0 * w / h))\n",
    "    th = 416 if h > w else int(np.round(416.0 * h / w))\n",
    "    frame = cv2.resize(frame, (tw, th))\n",
    "    pad_value=114\n",
    "    top = int(max(0, np.round((416.0 - th) / 2)))\n",
    "    left = int(max(0, np.round((416.0 - tw) / 2)))\n",
    "    bottom = 416 - top - th\n",
    "    right = 416 - left - tw\n",
    "    frame = cv2.copyMakeBorder(frame, top, bottom, left, right,\n",
    "                               cv2.BORDER_CONSTANT, value=[pad_value, pad_value, pad_value])\n",
    "    \n",
    "    frame = np.ascontiguousarray(np.array(frame, dtype=np.float32).transpose(2, 0, 1)) # HWC -> CHW\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "    return frame\n",
    "\n",
    "def run(msg):\n",
    "    # this is a dummy function required to satisfy AML-SDK requirements.\n",
    "    return msg\n",
    "\n",
    "def init():\n",
    "    # Choose HTTP, AMQP or MQTT as transport protocol.  Currently only MQTT is supported.\n",
    "    PROTOCOL = IoTHubTransportProvider.MQTT\n",
    "    DEVICE = 0 # when device is /dev/video0\n",
    "    LABEL_FILE = \"labels.txt\"\n",
    "    MODEL_FILE = \"Model.onnx\"\n",
    "    global MESSAGE_TIMEOUT # setting for IoT Hub Manager\n",
    "    MESSAGE_TIMEOUT = 1000\n",
    "    LOCAL_DISPLAY = \"OFF\" # flag for local display on/off, default OFF\n",
    "\n",
    "    \n",
    "    # Create the IoT Hub Manager to send message to IoT Hub\n",
    "    print(\"trying to make IOT Hub manager\")\n",
    "    \n",
    "    hub_manager = HubManager(PROTOCOL)\n",
    "\n",
    "    if not hub_manager:\n",
    "        print(\"Took too long to make hub_manager, exiting program.\")\n",
    "        print(\"Try restarting IotEdge or this module.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Get Labels from labels file \n",
    "    labels_file = open(LABEL_FILE)\n",
    "    labels_string = labels_file.read()\n",
    "    labels = labels_string.split(\",\")\n",
    "    labels_file.close()\n",
    "    label_lookup = {}\n",
    "    for i, val in enumerate(labels):\n",
    "        label_lookup[val] = i\n",
    "\n",
    "    # get model path from within the container image\n",
    "    model_path=Model.get_model_path(MODEL_FILE)\n",
    "    \n",
    "    # Loading ONNX model\n",
    "\n",
    "    print(\"loading model to ONNX Runtime...\")\n",
    "    start_time = time.time()\n",
    "    ort_session = rt.InferenceSession(model_path)\n",
    "    print(\"loaded after\", time.time()-start_time,\"s\")\n",
    "\n",
    "    # start reading frames from video endpoint\n",
    "    \n",
    "    cap = cv2.VideoCapture(DEVICE)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        _, _ = cap.read()\n",
    "        ret, img_frame = cap.read()       \n",
    "        if not ret:\n",
    "            print('no video RESETTING FRAMES TO 0 TO RUN IN LOOP')\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            continue\n",
    "        \n",
    "        \"\"\" \n",
    "        Handles incoming inference calls for each fames. Gets frame from request and calls inferencing function on frame.\n",
    "        Sends result to IOT Hub.\n",
    "        \"\"\"\n",
    "        try:\n",
    "                        \n",
    "            draw_frame = img_frame\n",
    "            start_time = time.time()\n",
    "            # pre-process the frame to flatten, scale for tiny-yolo\n",
    "            \n",
    "            frame = get_tinyyolo_frame_from_encode(img_frame)\n",
    "            \n",
    "            # run the inference session for the given input frame\n",
    "            objects = run_onnx(frame, ort_session, draw_frame, labels, LOCAL_DISPLAY)\n",
    "            \n",
    "            # LOOK AT OBJECTS AND CHECK PREVIOUS STATUS TO APPEND\n",
    "            num_objects = len(objects) \n",
    "            print(\"NUMBER OBJECTS DETECTED:\", num_objects)                               \n",
    "            print(\"PROCESSED IN:\",time.time()-start_time,\"s\")            \n",
    "            if num_objects > 0:\n",
    "                output_IOT = IoTHubMessage(json.dumps(objects))\n",
    "                hub_manager.forward_event_to_output(\"inferenceoutput\", output_IOT, 0)\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print('EXCEPTION:', str(e))\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Include the dependent packages required by the application scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_pip_package(\"azure-iothub-device-client\")\n",
    "myenv.add_pip_package(\"numpy\")\n",
    "myenv.add_pip_package(\"opencv-python\")\n",
    "myenv.add_pip_package(\"requests\")\n",
    "myenv.add_pip_package(\"pytz\")\n",
    "myenv.add_pip_package(\"onnx\")\n",
    "\n",
    "with open(\"myenv.yml\", \"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Build the custom container image with the ONNX Runtime + OpenVINO base image\n",
    "This step uses pre-built container images with ONNX Runtime and the different HW execution providers. A complete list of base images are located [here](https://github.com/microsoft/onnxruntime/tree/master/dockerfiles#docker-containers-for-onnx-runtime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Set the web service configuration (using default here)\n",
    "from azureml.core.model import InferenceConfig\n",
    "#from azureml.core.webservice import AksWebservice\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.environment import Environment, DEFAULT_GPU_IMAGE\n",
    "\n",
    "useContainerImage = True\n",
    "\n",
    "if useContainerImage:\n",
    "    openvino_image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "                                                           runtime = \"python\",\n",
    "                                                           dependencies=[\"labels.txt\", \"amlpackage_inference.py\"],\n",
    "                                                           conda_file = \"myenv.yml\",\n",
    "                                                           description = \"TinyYolo ONNX Runtime inference container\",\n",
    "                                                           tags = {\"demo\": \"onnx\"})\n",
    "\n",
    "    # Use the ONNX Runtime + OpenVINO base image for Intel MovidiusTM USB sticks\n",
    "    openvino_image_config.base_image = \"mcr.microsoft.com/azureml/onnxruntime:latest-openvino-myriad\" \n",
    "\n",
    "    # For the Intel Movidius VAD-M PCIe card use this:\n",
    "    # openvino_image_config.base_image = \"mcr.microsoft.com/azureml/onnxruntime:latest-openvino-vadm\"\n",
    "\n",
    "    openvino_image = ContainerImage.create(name = \"name-of-image\",\n",
    "                              # this is the model object\n",
    "                              models = [model],\n",
    "                              image_config = openvino_image_config,\n",
    "                              workspace = ws)\n",
    "\n",
    "    # Alternative: Re-use an image that you have already built from the workspace image registry\n",
    "    # openvino_image = ContainerImage(name = \"<name-of-image>\", workspace = ws)\n",
    "\n",
    "else:\n",
    "    env = Environment('deploytoedgeenv')\n",
    "    # Please see [Azure ML Containers repository](https://github.com/Azure/AzureML-Containers#featured-tags)\n",
    "    # for open-sourced GPU base images.\n",
    "    \n",
    "    env.docker.base_image = \"mcr.microsoft.com/azureml/onnxruntime:latest-openvino-myriad\"\n",
    "    #env.docker.base_image = DEFAULT_GPU_IMAGE\n",
    "\n",
    "    env.python.conda_dependencies = CondaDependencies.create(\n",
    "                            conda_packages=['tensorflow-gpu==1.12.0','numpy'],\n",
    "                            pip_packages=['azureml-defaults','azure-iothub-device-client','numpy','opencv-python','requests','pytz','onnx']\n",
    "                            )\n",
    "\n",
    "    inference_config = InferenceConfig(entry_script=\"score.py\", environment=env)\n",
    "    imagename= \"myopenvino-myriad\"\n",
    "    #imagename= \"myopenvino\"\n",
    "    imagelabel=\"1.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if useContainerImage:\n",
    "    openvino_image.wait_for_creation(show_output = True)\n",
    "    if openvino_image.creation_state == 'Failed':\n",
    "        print(\"Image build log at: \" + openvino_image.image_build_log_uri)\n",
    "else:\n",
    "    package = Model.package(ws, [model], inference_config=inference_config,image_name=imagename, image_label=imagelabel)\n",
    "    package.wait_for_creation(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if useContainerImage:\n",
    "    if openvino_image.creation_state != 'Failed':\n",
    "        print(\"Image URI at: \" +openvino_image.image_location)\n",
    "else:\n",
    "    print(\"ACR:\", package.get_container_registry)\n",
    "    print(\"Image:\", package.location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deploy to the UP<sup>2</sup> device using Azure IoT Edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Login with the Azure subscription to provision the IoT Hub and the IoT Edge device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login \n",
    "!az account set --subscription $ws.subscription_id \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the account\n",
    "!az account show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Specify the IoT Edge device details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter list to configure the IoT Hub and the IoT Edge device\n",
    "\n",
    "# Pick a name for what you want to call the module you deploy to the camera\n",
    "module_name = \"module-name-here\"\n",
    "\n",
    "# Resource group in Azure \n",
    "resource_group_name= ws.resource_group\n",
    "iot_rg=resource_group_name\n",
    "\n",
    "# Azure region where your services will be provisioned\n",
    "iot_location=\"location-here\"\n",
    "\n",
    "# Azure IoT Hub name\n",
    "iot_hub_name=\"name-of-IoT-Hub\"\n",
    "\n",
    "# Pick a name for your camera\n",
    "iot_device_id=\"name-of-IoT-Edge-device\"\n",
    "\n",
    "# Pick a name for the deployment configuration\n",
    "iot_deployment_id=\"Infernce Module from AML\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2a Optional: Provision the IoT Hub, create the IoT Edge device and Setup the Intel UP<sup>2</sup> AI Vision Developer Kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az iot hub create --resource-group $resource_group_name --name $iot_hub_name --sku S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register an IoT Edge device (create a new entry in the Iot Hub)\n",
    "!az iot hub device-identity create --hub-name $iot_hub_name --device-id $iot_device_id --edge-enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az iot hub device-identity show-connection-string --hub-name $iot_hub_name --device-id $iot_device_id "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps need to be executed in the device terminal\n",
    "\n",
    "1. Open the IoT edge configuration file in UP<sup>2</sup> device to update the IoT Edge device *connection string*\n",
    "    \n",
    "    `sudo nano /etc/iotedge/config.yaml`\n",
    "    \n",
    "        provisioning:\n",
    "        source: \"manual\"\n",
    "        device_connection_string: \"<ADD DEVICE CONNECTION STRING HERE>\"\n",
    "\n",
    "2. To update the DPS TPM provisioning configuration:\n",
    "\n",
    "        provisioning:\n",
    "        source: \"dps\"\n",
    "        global_endpoint: \"https://global.azure-devices-provisioning.net\"\n",
    "        scope_id: \"{scope_id}\"\n",
    "        attestation:\n",
    "        method: \"tpm\"\n",
    "        registration_id: \"{registration_id}\"\n",
    "\n",
    "3. Save and close the file. `CTRL + X, Y, Enter\n",
    "\n",
    "    \n",
    "4. After entering the privisioning information in the configuration file, restart the *iotedge* daemon\n",
    "    \n",
    "    `sudo systemctl restart iotedge`\n",
    "    \n",
    "    \n",
    "5. We will show the object detection results from the camera connected (`/dev/video0`) to the UP<sup>2</sup> on the display. Update your .profile file:\n",
    "    \n",
    "    `nano ~/.profile`\n",
    "    \n",
    "   add the following line to the end of file\n",
    "\n",
    "    __xhost +__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Construct the deployment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the registry uri\n",
    "container_reg = ws.get_details()[\"containerRegistry\"]\n",
    "reg_name=container_reg.split(\"/\")[-1]\n",
    "container_url = \"\\\"\" + openvino_image.image_location + \"\\\",\"\n",
    "subscription_id = ws.subscription_id\n",
    "print('{}'.format(openvino_image.image_location), \"<-- this is the URI configured in the IoT Hub for the device\")\n",
    "print('{}'.format(reg_name))\n",
    "print('{}'.format(subscription_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.mgmt.containerregistry import ContainerRegistryManagementClient\n",
    "from azure.mgmt import containerregistry\n",
    "client = ContainerRegistryManagementClient(ws._auth,subscription_id)\n",
    "result= client.registries.list_credentials(resource_group_name, reg_name, custom_headers=None, raw=False)\n",
    "username = result.username\n",
    "password = result.passwords[0].value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the `deplpyment.json` with the AML image registry details\n",
    "We have provided here a sample deployment template this reference implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./aml-deployment.template.json')\n",
    "contents = file.read()\n",
    "contents = contents.replace('__AML_MODULE_NAME', module_name)\n",
    "contents = contents.replace('__AML_REGISTRY_NAME', reg_name)\n",
    "contents = contents.replace('__AML_REGISTRY_USER_NAME', username)\n",
    "contents = contents.replace('__AML_REGISTRY_PASSWORD', password)\n",
    "contents = contents.replace('__AML_REGISTRY_IMAGE_LOCATION', openvino_image.image_location)\n",
    "with open('./deployment.json', 'wt', encoding='utf-8') as output_file:\n",
    "    output_file.write(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Push the *deployment* to the IoT Edge device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pushing deployment to IoT Edge device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Set the deployement\") \n",
    "!az iot edge set-modules --device-id $iot_device_id --hub-name $iot_hub_name --content deployment.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Monitor IoT Hub Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az iot hub monitor-events --hub-name $iot_hub_name -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CLEANUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm score.py deployment.json myenv.yml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "39125b5409e0292efda8286b395f6798cb9e5762b6be52e7612d25cf7547bdfe"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}