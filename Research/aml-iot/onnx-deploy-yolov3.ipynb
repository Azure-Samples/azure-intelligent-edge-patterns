{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/deployment/onnx/onnx-convert-aml-deploy-tinyyolo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Real-time Object Detection using ONNX on AzureML\n",
    "\n",
    "This example shows how to use the YOLO v3 model as a web service using Azure Machine Learning services and the ONNX Runtime.\n",
    "\n",
    "## What is ONNX\n",
    "ONNX is an open format for representing machine learning and deep learning models. ONNX enables open and interoperable AI by enabling data scientists and developers to use the tools of their choice without worrying about lock-in and flexibility to deploy to a variety of platforms. ONNX is developed and supported by a community of partners including Microsoft, Facebook, and Amazon. For more information, explore the [ONNX website](http://onnx.ai).\n",
    "\n",
    "## YOLO Details\n",
    "You Only Look Once (YOLO) is a state-of-the-art, real-time object detection system. For more information about YOLO, please visit the [YOLO website](https://pjreddie.com/darknet/yolo/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To make the best use of your time, make sure you have done the following:\n",
    "\n",
    "* Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning\n",
    "* Follow the instructions in the readme file before going through the steps in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download YOLO v3 ONNX model \n",
    "\n",
    "First we download the model. This may take a few minutes. The model will be downloaded to the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "onnx_model_url = \"https://onnxzoo.blob.core.windows.net/models/opset_10/yolov3/yolov3.onnx\"\n",
    "urllib.request.urlretrieve(onnx_model_url, filename=\"yolov3.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Azure ML workspace\n",
    "\n",
    "We begin by instantiating a workspace object from the existing workspace created in the configuration notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering your model with Azure ML\n",
    "\n",
    "Now we upload the model and register it in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path = \"yolov3.onnx\",\n",
    "                       model_name = \"yolov3\",\n",
    "                       tags = {\"onnx\": \"yolov3\"},\n",
    "                       description = \"YOLOv3 from ONNX Model Zoo\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying your registered models\n",
    "\n",
    "You can optionally list out all the models that you have registered in this workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ws.models\n",
    "for name, m in models.items():\n",
    "    print(\"Name:\", name,\"\\tVersion:\", m.version, \"\\tDescription:\", m.description, m.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write scoring file\n",
    "\n",
    "We are now going to deploy our ONNX model on Azure ML using the ONNX Runtime. We begin by writing a score.py file that will be invoked by the web service call. The `init()` function is called once when the container is started so we load the model using the ONNX Runtime into a global session object. The `run()` function is called when the webservice is invoked for inferencing. After running the code below you should see a score.py file in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from azureml.core.model import Model\n",
    "import numpy as np    # we're going to use numpy to process input and output data\n",
    "import onnxruntime    # to inference ONNX models, we use the ONNX Runtime\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def init():\n",
    "    global session\n",
    "    model = Model.get_model_path(model_name = 'yolov3')\n",
    "    session = onnxruntime.InferenceSession(model)\n",
    "\n",
    "def letterbox_image(image, size):\n",
    "    '''resize image with unchanged aspect ratio using padding'''\n",
    "    iw, ih = image.size\n",
    "    w, h = size\n",
    "    scale = min(w/iw, h/ih)\n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "\n",
    "    image = image.resize((nw,nh), Image.BICUBIC)\n",
    "    new_image = Image.new('RGB', size, (128,128,128))\n",
    "    new_image.paste(image, ((w-nw)//2, (h-nh)//2))\n",
    "    return new_image\n",
    "\n",
    "\n",
    "    \n",
    "def preprocess(input_data_json):\n",
    "    # convert the JSON data into the tensor input    \n",
    "    imgb64 = json.loads(input_data_json)['data']    \n",
    "    \n",
    "    # Base64 decoding\n",
    "    image_64_decode = base64.b64decode(imgb64)\n",
    "    \n",
    "    # Open the image \n",
    "    img = Image.open(io.BytesIO(image_64_decode))\n",
    "    \n",
    "    \n",
    "    model_image_size = (416, 416)\n",
    "    \n",
    "    # Get the resized image\n",
    "    boxed_image = letterbox_image(img, tuple(reversed(model_image_size)))\n",
    "    \n",
    "    # Convert image to numpy array\n",
    "    image_data = np.array(boxed_image, dtype='float32')\n",
    "    \n",
    "    # Normalize image\n",
    "    image_data /= 255.\n",
    "    \n",
    "     # Array has shape height x width x channel. We need to transpose it to channel x width x height            \n",
    "    image_data = np.transpose(image_data, [2, 0, 1])\n",
    "    \n",
    "    # Add another dimension to make it an array of images    \n",
    "    image_data = np.expand_dims(image_data, 0)\n",
    "    \n",
    "    image_size = np.array([img.size[1], img.size[0]], dtype=np.float32).reshape(1, 2)          \n",
    "    \n",
    "    return image_data, image_size\n",
    "\n",
    "def postprocess(result):\n",
    "    #r = np.array(result)\n",
    "    boxes = result[0]\n",
    "    scores = result[1]\n",
    "    indices = result[2]\n",
    "   \n",
    "    \n",
    "    out_boxes, out_scores, out_classes = [], [], []\n",
    "    for idx_ in indices:\n",
    "        out_classes.append(idx_[1].tolist())\n",
    "        out_scores.append(scores[tuple(idx_)].tolist())\n",
    "        idx_1 = (idx_[0], idx_[2])\n",
    "        out_boxes.append(boxes[idx_1].tolist())    \n",
    "                   \n",
    "    er = {'boxes':out_boxes, 'scores':out_scores, 'classes':out_classes}\n",
    "\n",
    "    \n",
    "    return json.dumps(er)\n",
    "\n",
    "def run(input_data_json):\n",
    "    try:\n",
    "        start = time.time()   # start timer\n",
    "        image_data, image_size = preprocess(input_data_json)\n",
    "        \n",
    "        input_feeds = {}\n",
    "        input_feeds[session.get_inputs()[0].name] = image_data\n",
    "        input_feeds[session.get_inputs()[1].name] = image_size\n",
    "        \n",
    "        #input_name = session.get_inputs()[0].name  # get the id of the first input of the model   \n",
    "        result = session.run([], input_feeds)\n",
    "        end = time.time()     # stop timer\n",
    "        return {\"result\": postprocess(result),\n",
    "                \"time\": end - start}\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return {\"error\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dependencies file\n",
    "Create a YAML file that specifies which dependencies we would like to see in our container. After running the code below you should see myenv.yml in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies.create(pip_packages=[\"numpy\",\"pillow\", \"onnxruntime\",\"azureml-defaults\", \"azureml-core\"])\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create container image in Azure ML\n",
    "Use Azure ML to create the container image. This step will likely take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig, Model\n",
    "\n",
    "# Create inference configuration. This creates a docker image that contains the model.\n",
    "inference_config = InferenceConfig(runtime=\"python\",\n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"myenv.yml\")\n",
    "\n",
    "# Builds an image in ACR.\n",
    "# TODO: Move to 1.12.0 SDK version, and specify image name, and tag.\n",
    "package = Model.package(ws, [model], inference_config)\n",
    "package.wait_for_creation(show_output=True)\n",
    "\n",
    "print(\"ACR:\", package.get_container_registry)\n",
    "print(\"Image:\", package.location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Azure IoT Edge device\n",
    "\n",
    "Follow [documentation](https://docs.microsoft.com/en-us/azure/iot-edge/quickstart-linux) to setup a Linux VM as an Azure IoT Edge device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy container to Azure IoT Edge device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "acr_name = package.location.split(\"/\")[0]\n",
    "reg_name = acr_name.split(\".\")[0]\n",
    "subscription_id = ws.subscription_id\n",
    "\n",
    "print('{}'.format(acr_name))\n",
    "print('{}'.format(subscription_id))\n",
    "\n",
    "# TODO: Derive image_location through code.\n",
    "image_location = \"<Fill image URL from ACR>\"\n",
    "\n",
    "print('{}'.format(image.image_location))\n",
    "\n",
    "# Fetch username, password of ACR.\n",
    "from azure.mgmt.containerregistry import ContainerRegistryManagementClient\n",
    "from azure.mgmt import containerregistry\n",
    "\n",
    "client = ContainerRegistryManagementClient(ws._auth,subscription_id)\n",
    "result= client.registries.list_credentials(ws.resource_group, reg_name, custom_headers=None, raw=False)\n",
    "\n",
    "username = result.username\n",
    "password = result.passwords[0].value\n",
    "\n",
    "print(username)\n",
    "print(password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a deployment.json file using the template json. Then push the deployment json file to the IoT Hub, which will then send it to the IoT Edge device. The IoT Edge agent will then pull the Docker images and run them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "module_name = \"yolov3\"\n",
    "\n",
    "file = open('iotedge-yolov3-template.json')\n",
    "contents = file.read()\n",
    "contents = contents.replace('__MODULE_NAME', module_name)\n",
    "contents = contents.replace('__REGISTRY_NAME', reg_name)\n",
    "contents = contents.replace('__REGISTRY_USER_NAME', username)\n",
    "contents = contents.replace('__REGISTRY_PASSWORD', password)\n",
    "contents = contents.replace('__REGISTRY_IMAGE_LOCATION', image_location)\n",
    "with open('./deployment.json', 'wt', encoding='utf-8') as output_file:\n",
    "    output_file.write(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter your the IoT device id and the IoT Hub name in the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push the deployment JSON to the IOT Hub\n",
    "!az iot edge set-modules --device-id <IoTdeviceid> --hub-name <IoTHubName> --content deployment.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Before testing, open up inbound port 5001 on your Edge device. You can use [Azure Portal](https://docs.microsoft.com/en-us/azure/virtual-machines/windows/nsg-quickstart-portal) for this purpose. \n",
    "Update the scoring URI with the edge device public IP address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "scoring_uri = 'http://<EdgeDeviceIPAddress>:5001/score'\n",
    "\n",
    "# You cannot send a byte array in JSON and hence need to decode it to UTF-8\n",
    "input_data = json.dumps({'data': image_64_encode.decode(\"utf-8\")})\n",
    "\n",
    "try:\n",
    "    \n",
    "    # Set the content type\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    # Make the request and display the response\n",
    "    resp = requests.post(scoring_uri, input_data, headers=headers)    \n",
    "    \n",
    "    plotImageWithBBoxesAndLabels(resp.text, downloaded_imagefile)\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "viswamy"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}