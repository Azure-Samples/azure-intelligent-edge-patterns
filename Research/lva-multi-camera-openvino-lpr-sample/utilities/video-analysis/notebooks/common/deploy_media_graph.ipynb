{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Media Graph\n",
    "\n",
    "In this section, we will deploy media graphs onto our IoT Edge device to trigger our modules to perform certain actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy / Manage Media Graph on LVA Edge Module\n",
    "At this stage of the sample, we should have all required modules deployed to the Edge device, up and running.  \n",
    "\n",
    "Now we will deploy media graphs onto the \"lvaEdge\" module. Here, \"lvaEdge\" is the name that we assigned to the LVA module inside the module deployment template json file from the [previous sample](08_deploy_iotedge_modules.ipynb). Media graph is also a Json file that defines a media flow pipeline from media sources to the target sinks and any analytics processes in-between. The media graph file consists of following modules:  \n",
    "\n",
    "```\n",
    "{\n",
    "    \"@apiVersion\": \"1.0\",\n",
    "\n",
    "    \"name\": \"SampleMediaGraphOrganization\",\n",
    "\n",
    "    \"properties\":{\n",
    "\n",
    "        \"parameters\": ...\n",
    "\n",
    "        \"sources\": ...\n",
    "\n",
    "        \"processes\": ...\n",
    "\n",
    "        \"sinks\": ...\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "In the media graph Json file above, the \"parameters\" section is the most critical part of the media graph. The \"parameters\" section defines all required parameters to run the media graph. In this section, we will define the addresses of the media sources, their access credentials, and the parameters related to the process modules, such as fps rate and sensitivity of motion detection. Each media graph may have a different media flow, i.e., one may have a motion detection processor while another may not. You may modify this media graph according to your needs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Media Graph\n",
    "In this sample project, we provide a sample media graph file [template.json](../../../../MediaGraph/topologies/motion-with-httpExtension/topology.json) under the MediaGraph/topologies/motion-with-httpExtension folder.  The media graph in this file ingests a video stream from a single IP camera, runs motion detector processor on the stream, and sends the stream to one of two targets if there is motion. The first target is Azure Media Services, a cloud platform that can archive the stream's motion chunks. The other possible target is the custom AI module that we developed previous sections of this sample; the AI module analyzes the stream (a chunk with motion) and then sends the result (a Json-format inference result) to IoT Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Parameters in Media Graph\n",
    "There are two ways to set parameters in the media graph:  \n",
    "1. Update the default values of the parameters in \"template.json\", which is **not** the prefered method. \n",
    "2. Note the parameter names and data types in \"template.json\", and override their values in the deployment command that we will show in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Media Graph with Custom Parameters\n",
    "Below, we will explain the following operations:\n",
    "1. Setting (deploying) Media Graph Topology on the IoT Edge Device's lvaEdge module\n",
    "2. Creating a Media Topolgy Instance from the one set in step 1\n",
    "3. Activate the Topology Instance that set in step 2\n",
    "\n",
    "We will also show how to\n",
    "* List and delete the already set Graph Topologies on the Device\n",
    "* List and delete the already set Graph Instances on the Device\n",
    "* Acticate / deactivate the Graph Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Prerequisites\n",
    "We will use a simple Python script to deploy our media graph Json file into the \"lvaEdge\" module. Our process entails sending a file into the IoT Edge device over the Internet through a IoT Edge Hub service. To do so, we need to install following Python packages. These packages were developed by Microsoft and help with interacting with IoT Hub Services.\n",
    "\n",
    "!Important: As mentioned in the first section of this tutorial, you must use the right ```pip``` command (```pip``` or ```pip3```) depending on your Python installation. This sample is tested with Python version 3.6 and so we use the ```pip3``` command to install the packages into our Python3 environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-iot-device\n",
      "  Downloading azure_iot_device-2.1.4-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.20.0 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from azure-iot-device) (2.22.0)\n",
      "Collecting requests-unixsocket<1.0.0,>=0.1.5\n",
      "  Downloading requests_unixsocket-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting paho-mqtt<2.0.0,>=1.4.0\n",
      "  Downloading paho-mqtt-1.5.0.tar.gz (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 3.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>1.21.1; python_version != \"3.4\" in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from azure-iot-device) (1.25.8)\n",
      "Requirement already satisfied: six<2.0.0,>=1.12.0 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from azure-iot-device) (1.14.0)\n",
      "Collecting janus==0.4.0; python_version >= \"3.5\"\n",
      "  Downloading janus-0.4.0-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: PySocks in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from azure-iot-device) (1.7.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from requests<3.0.0,>=2.20.0->azure-iot-device) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from requests<3.0.0,>=2.20.0->azure-iot-device) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from requests<3.0.0,>=2.20.0->azure-iot-device) (2020.6.20)\n",
      "Building wheels for collected packages: paho-mqtt\n",
      "  Building wheel for paho-mqtt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for paho-mqtt: filename=paho_mqtt-1.5.0-py3-none-any.whl size=61415 sha256=8ada862a1071dda31fb4d305f8c0771d2b6a00f12874094354f3643d80410ca1\n",
      "  Stored in directory: /home/visionadmin/.cache/pip/wheels/0d/7c/fb/05123381bd60c57ffcdc6fcc1c26e585dedee85b8c1625e2c1\n",
      "Successfully built paho-mqtt\n",
      "Installing collected packages: requests-unixsocket, paho-mqtt, janus, azure-iot-device\n",
      "Successfully installed azure-iot-device-2.1.4 janus-0.4.0 paho-mqtt-1.5.0 requests-unixsocket-0.2.0\n",
      "Collecting azure-iot-hub\n",
      "  Downloading azure_iot_hub-2.2.1-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting uamqp\n",
      "  Downloading uamqp-1.2.9-cp37-cp37m-manylinux2010_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 16.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: msrest in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from azure-iot-hub) (0.6.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from uamqp->azure-iot-hub) (2020.6.20)\n",
      "Requirement already satisfied: six~=1.0 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from uamqp->azure-iot-hub) (1.14.0)\n",
      "Requirement already satisfied: requests~=2.16 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from msrest->azure-iot-hub) (2.22.0)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from msrest->azure-iot-hub) (0.6.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from msrest->azure-iot-hub) (1.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from requests~=2.16->msrest->azure-iot-hub) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from requests~=2.16->msrest->azure-iot-hub) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from requests~=2.16->msrest->azure-iot-hub) (2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from requests-oauthlib>=0.5.0->msrest->azure-iot-hub) (3.1.0)\n",
      "Installing collected packages: uamqp, azure-iot-hub\n",
      "Successfully installed azure-iot-hub-2.2.1 uamqp-1.2.9\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-iot-device\n",
    "!pip install azure-iot-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import A Helper Python Class to Deploy Media Graphs\n",
    "The following code snippet will import a custom Python class to help us deploy media edge graphs. After the import, we will instantiate a graph manager object with IoT Hub, IoT Edge Device, and Graph API version details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env_variables import *\n",
    "from graph_manager import GraphManager\n",
    "\n",
    "moduleId = \"lvaEdge\" # Must be same as the name that we assigned to LVA module in the deployment manifest file\n",
    "operationsApiVersion = \"1.0\"  # Must be same as the version number in the deployment manifest file\n",
    "\n",
    "graphManager = GraphManager(iotHubConnString, iotDeviceId, moduleId, operationsApiVersion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Existing Graph Topologies and Instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'status': 200, 'payload': {'value': []}}\n"
     ]
    }
   ],
   "source": [
    "# List topologies\n",
    "response = graphManager.GenericCall(\"GraphTopologyList\", {})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'status': 200, 'payload': {'value': []}}\n"
     ]
    }
   ],
   "source": [
    "# List instances\n",
    "response = graphManager.GenericCall(\"GraphInstanceList\", {})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Topology\n",
    "The following code snippet will deploy the \"template.json\" file into the lvaEdge module running on our IoT Edge device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can define a topologyFile or a topologyUrl that you want to deploy into the module. Here we point to our sample Media Graph Topology File.\n",
    "operationParams = {\n",
    "                    \"topologyFile\": \"../../../../MediaGraph/topologies/motion-with-httpExtension/topology.json\"\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'status': 201, 'payload': {'systemData': {'createdAt': '2020-07-07T19:20:29.085Z', 'lastModifiedAt': '2020-07-07T19:20:29.085Z'}, 'name': 'EVROnMotionPlusHttpExtension', 'properties': {'description': 'Event-based video recording to Assets based on motion events, and using HTTP Extension to send images to an external inference engine', 'parameters': [{'name': 'rtspUserName', 'type': 'String', 'description': 'rtsp source user name.', 'default': 'dummyUserName'}, {'name': 'rtspPassword', 'type': 'String', 'description': 'rtsp source password.', 'default': 'dummyPassword'}, {'name': 'rtspUrl', 'type': 'String', 'description': 'rtsp Url'}, {'name': 'motionSensitivity', 'type': 'String', 'description': 'motion detection sensitivity', 'default': 'medium'}, {'name': 'httpAIServerAddress', 'type': 'String', 'description': 'AI Server Address', 'default': 'http://yolov3/score'}, {'name': 'hubSinkOutputName', 'type': 'String', 'description': 'hub sink output name', 'default': 'inferenceOutput'}, {'name': 'imageEncoding', 'type': 'String', 'description': 'image encoding for frames', 'default': 'bmp'}, {'name': 'imageScaleMode', 'type': 'String', 'description': 'image scaling mode', 'default': 'preserveAspectRatio'}, {'name': 'frameWidth', 'type': 'String', 'description': 'Width of the video frame to be received from LVA.', 'default': '416'}, {'name': 'frameHeight', 'type': 'String', 'description': 'Height of the video frame to be received from LVA.', 'default': '416'}, {'name': 'frameRate', 'type': 'String', 'description': 'Rate of the frames per second to be received from LVA.', 'default': '2'}], 'sources': [{'@type': '#Microsoft.Media.MediaGraphRtspSource', 'name': 'rtspSource', 'transport': 'Tcp', 'endpoint': {'@type': '#Microsoft.Media.MediaGraphUnsecuredEndpoint', 'url': '${rtspUrl}', 'credentials': {'@type': '#Microsoft.Media.MediaGraphUsernamePasswordCredentials', 'username': '${rtspUserName}'}}}], 'processors': [{'@type': '#Microsoft.Media.MediaGraphMotionDetectionProcessor', 'sensitivity': '${motionSensitivity}', 'name': 'motionDetection', 'inputs': [{'nodeName': 'rtspSource', 'outputSelectors': []}]}, {'@type': '#Microsoft.Media.MediaGraphFrameRateFilterProcessor', 'maximumFps': '${frameRate}', 'name': 'frameRateFilter', 'inputs': [{'nodeName': 'motionDetection', 'outputSelectors': []}]}, {'@type': '#Microsoft.Media.MediaGraphSignalGateProcessor', 'activationEvaluationWindow': 'PT1S', 'activationSignalOffset': 'PT0S', 'minimumActivationTime': 'PT30S', 'maximumActivationTime': 'PT30S', 'name': 'signalGateProcessor', 'inputs': [{'nodeName': 'motionDetection', 'outputSelectors': []}, {'nodeName': 'rtspSource', 'outputSelectors': []}]}, {'@type': '#Microsoft.Media.MediaGraphHttpExtension', 'endpoint': {'@type': '#Microsoft.Media.MediaGraphUnsecuredEndpoint', 'url': '${httpAIServerAddress}', 'credentials': {'@type': '#Microsoft.Media.MediaGraphUsernamePasswordCredentials', 'username': 'user'}}, 'image': {'scale': {'mode': '${imageScaleMode}', 'width': '${frameWidth}', 'height': '${frameHeight}'}, 'format': {'@type': '#Microsoft.Media.MediaGraphImageFormatEncoded', 'encoding': '${imageEncoding}'}}, 'name': 'httpExtension', 'inputs': [{'nodeName': 'frameRateFilter', 'outputSelectors': []}]}], 'sinks': [{'@type': '#Microsoft.Media.MediaGraphAssetSink', 'localMediaCachePath': '/var/lib/azuremediaservices/tmp/', 'localMediaCacheMaximumSizeMiB': '2048', 'segmentLength': 'PT30S', 'assetNamePattern': 'sampleAssetFromEVR-LVAEdge-${System.DateTime}', 'name': 'assetSink', 'inputs': [{'nodeName': 'signalGateProcessor', 'outputSelectors': []}]}, {'@type': '#Microsoft.Media.MediaGraphIoTHubMessageSink', 'hubOutputName': '${hubSinkOutputName}', 'name': 'hubSink', 'inputs': [{'nodeName': 'httpExtension', 'outputSelectors': []}]}]}}}\n"
     ]
    }
   ],
   "source": [
    "# Set Graph Topology\n",
    "response = graphManager.GraphTopologySet(operationParams)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Topology Instance\n",
    "\n",
    "The following code snippet will set the values of the parameters mentioned in \"template.json\" and will create a Topology Instance. If you modify the topology or add new parameters, you should update the parameter list below accordingly.  \n",
    "\n",
    ">[!IMPORTANT]  \n",
    ">- Be sure that the value of \"topologyName\" parameter below and the same parameter in the \"template.json\" file are the same.  \n",
    ">- Since we don't have a physical IP camera set for this sample, we use a virtual IP camera simulator. In the previous steps when we deployed the module deployment manifest, we already deployed a simulator module which plays \"lots_284.mkv\" video file as if played from an IP camera. Thus, in the parameter list below, the parameter \"rtspUrl\" points to the URL address of this IoT Module (rtsp://rtspsim:554) with the full path of the video file that we want to play. You can replace this parameter's value with full RTSP address of your phyical IP camera.  \n",
    ">- rtspUsername and rtspPassword are dummy values for our simulator because they do not require authentication. However, if your source stream (i.e., your phyical IP Camera) requires authentication, then put the appropriate values for these parameters.  \n",
    ">- The value of the \"motionSensitivity\" parameter can be one of: {low, medium, high}. As the name implies, it sets the sensitivity of the motion detection processor.\n",
    ">- The value of the \"grpcAIServerAddress\" parameter points to the address of the inference server. The name of the module that we developed in this sample and deployed in our module deployment manifest was set to \"isServer\", which was listening to an inference request on \"/score\" endpoint through port 44001. Here, we set the exact address of the scoring endpoint.\n",
    ">- The \"hubSinkOutputName\" parameter sets the IoT Hub channel name which ingests inference results into IoT Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediaGraphTopologyParameters = {\n",
    "          \"name\": \"Sample-Graph-1\",\n",
    "          \"properties\": {\n",
    "            \"topologyName\": \"EVROnMotionPlusHttpExtension\",\n",
    "            \"description\": \"Sample graph description\",\n",
    "            \"parameters\": [\n",
    "              {\n",
    "                \"name\": \"rtspUserName\",\n",
    "                \"value\": \"username\"\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"rtspPassword\",\n",
    "                \"value\": \"password\"\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"rtspUrl\",\n",
    "                \"value\": \"rtsp://rtspsim:554/media/lots_284.mkv\"\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"motionSensitivity\",\n",
    "                \"value\": \"medium\"\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"httpAIServerAddress\",\n",
    "                \"value\": \"http://isEdge:5001/score\"\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"hubSinkOutputName\",\n",
    "                \"value\": \"inferences\"\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"imageEncoding\",\n",
    "                \"value\": \"jpeg\"\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"imageScaleMode\",\n",
    "                \"value\": \"pad\"\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting the parameters above (as Python dictionary data structure), we can now set an instance of the previously deployed topology on the Edge device with the custom parameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'status': 201, 'payload': {'systemData': {'createdAt': '2020-07-07T19:21:35.760Z', 'lastModifiedAt': '2020-07-07T19:21:35.760Z'}, 'name': 'Sample-Graph-1', 'properties': {'state': 'Inactive', 'description': 'Sample graph description', 'topologyName': 'EVROnMotionPlusHttpExtension', 'parameters': [{'name': 'rtspUserName', 'value': 'username'}, {'name': 'rtspPassword', 'value': 'password'}, {'name': 'rtspUrl', 'value': 'rtsp://rtspsim:554/media/lots_284.mkv'}, {'name': 'motionSensitivity', 'value': 'medium'}, {'name': 'httpAIServerAddress', 'value': 'http://isEdge:5001/score'}, {'name': 'hubSinkOutputName', 'value': 'inferences'}, {'name': 'imageEncoding', 'value': 'jpeg'}, {'name': 'imageScaleMode', 'value': 'pad'}]}}}\n"
     ]
    }
   ],
   "source": [
    "# Set topology instance\n",
    "response = graphManager.GenericCall(\"GraphInstanceSet\", mediaGraphTopologyParameters)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate Topology Instance\n",
    "Next, we activate the Topology Instance that we set in the previous node.\n",
    "\n",
    ">[!IMPORTANT]  \n",
    ">Be sure to set the name parameter below to the exact topology instance name that we used in the previous node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'status': 200, 'payload': None}\n"
     ]
    }
   ],
   "source": [
    "# Activate topology instance\n",
    "operationParams = {\n",
    "                    \"name\": \"Sample-Graph-1\"\n",
    "                    }\n",
    "\n",
    "response = graphManager.GenericCall(\"GraphInstanceActivate\", operationParams)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "If all the code cells above have successfully finished running, return to the Readme page to continue.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
