{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": [
        "# Create a CPU Accelerated YoloV3 Inference Engine\n",
        "In this section, we will create an inference engine wrapper, a class that will get image data as input, analyze it, and return the analysis result."
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Get Global Variables\n",
        "\n",
        "First, read the previously stored variables. We need the name of the directory that will be used to store our ML solution files. If this directory does not exist, we will create a directory with a specified directory name."
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('../../../common')\n",
        "from env_variables import *\n",
        "\n",
        "import os\n",
        "if not os.path.exists(isSolutionPath):\n",
        "    os.mkdir(isSolutionPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Download the ONNX ML Model\n",
        "Next, we will download the sample ONNX model to use in the solution. Recall that in this sample, we will be using YoloV3, an object detection ML model. However, you may customize this ML model to fit your needs."
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# Do not change the values below, as the names are embedded into the score.py file.\n",
        "# If the values are changed, you must also update the score.py content according to new file names\n",
        "onnxModelFileName = \"model.onnx\"\n",
        "onnxLabelFileName = \"labels.txt\"\n",
        "\n",
        "onnxModelUrl = \"https://media.githubusercontent.com/media/onnx/models/master/vision/object_detection_segmentation/yolov3/model/yolov3-10.onnx\"\n",
        "onnxModelLabels = \"https://raw.githubusercontent.com/qqwweee/keras-yolo3/master/model_data/coco_classes.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code snippet below downloads the YoloV3 model from the [ONNX Model Zoo](https://github.com/onnx/models) repository. \n",
        "\n",
        "> <span>[!NOTE]</span>\n",
        "> The model download URLs frequently change, so if any of the code below fails, please update the source URLs accordingly."
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# Download the model files\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "# Download the Yolo V3 pre-trained model\n",
        "isSolutionModelFilePath = os.path.join(isSolutionPath, onnxModelFileName)\n",
        "if not os.path.exists(isSolutionModelFilePath):\n",
        "    res = urllib.request.urlretrieve(onnxModelUrl, isSolutionModelFilePath)\n",
        "    print(\"Model file downloaded at: {}\".format(isSolutionModelFilePath))\n",
        "else:\n",
        "    print(\"{} already exists here, so not downloading again.\".format(isSolutionModelFilePath))\n",
        "    \n",
        "# Download the labels of the Yolo V3 pre-trained model\n",
        "isSolutionModelLabelFilePath = os.path.join(isSolutionPath, onnxLabelFileName)\n",
        "if not os.path.exists(isSolutionModelLabelFilePath):\n",
        "    res = urllib.request.urlretrieve(onnxModelLabels, isSolutionModelLabelFilePath)\n",
        "    print(\"Labels file downloaded at: {}\".format(isSolutionModelLabelFilePath))\n",
        "else:\n",
        "    print(\"{} already exists here, so not downloading again.\".format(isSolutionModelLabelFilePath))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Create Inference Engine Wrapper\n",
        "Next, we will create a class that with different properties and methods to help scoring and analysing data from an image. This class will also help us specify analytics compute targets, such as CPU, VPU, FPGA, and debugging features.  \n",
        "\n",
        "> <span style=\"color:red; font-weight: bold\"> [!IMPORTANT] </span>\n",
        "> Specific to this sample, we are using the YoloV3 model. As you can see from the code below,  \n",
        "> * The YoloV3 model accepts only raw image bytes with 416 by 416 in size.  \n",
        "> * Because we expect the `score` method to receive raw bytes of this size (416x416), we have statically coded the image size into our code. If the image is not 416x416 float32, then the code will crash.\n",
        "> * Why do we statically code the image size? LVA sends video frames to the `score` endpoint. In fact, LVA can send any image size and format. Since LVA can send images with 416x416 size, we do not need to spend additional compute cycles for re-sizing an image."
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "%%writefile $isSolutionPath/score.py\n",
        "import threading\n",
        "import cv2\n",
        "import numpy as np\n",
        "import io\n",
        "import onnxruntime\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import linecache\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "\n",
        "def PrintGetExceptionDetails():\n",
        "    exType, exValue, exTraceback = sys.exc_info()\n",
        "\n",
        "    tbFrame = exTraceback.tb_frame\n",
        "    lineNo = exTraceback.tb_lineno\n",
        "    fileName = tbFrame.f_code.co_filename\n",
        "\n",
        "    linecache.checkcache(fileName)\n",
        "    line = linecache.getline(fileName, lineNo, tbFrame.f_globals)\n",
        "\n",
        "    exMessage = '[IS] Exception:\\n\\tFile name: {0}\\n\\tLine number: {1}\\n\\tLine: {2}\\n\\tValue: {3}'.format(fileName, lineNo, line.strip(), exValue)\n",
        "\n",
        "    logging.info(exMessage)\n",
        "\n",
        "\n",
        "class MLModel:\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            self._modelFileName = 'model.onnx'\n",
        "            self._labelFileName = 'labels.txt'\n",
        "            self._lock = threading.Lock()\n",
        "\n",
        "            with open(self._labelFileName, \"r\") as f:\n",
        "                self._labelList = [l.rstrip() for l in f]\n",
        "            \n",
        "            self._onnxSession = onnxruntime.InferenceSession(self._modelFileName)\n",
        "\n",
        "        except:\n",
        "            PrintGetExceptionDetails()\n",
        "\n",
        "    def Preprocess(self, cvImage):\n",
        "        try:\n",
        "            imageBlob = cv2.cvtColor(cvImage, cv2.COLOR_BGR2RGB)\n",
        "            imageBlob = np.array(imageBlob, dtype='float32')\n",
        "            imageBlob /= 255.\n",
        "            imageBlob = np.transpose(imageBlob, [2, 0, 1])\n",
        "            imageBlob = np.expand_dims(imageBlob, 0)\n",
        "\n",
        "            return imageBlob\n",
        "        except:\n",
        "            PrintGetExceptionDetails()\n",
        "\n",
        "    def Postprocess(self, boxes, scores, indices):\n",
        "        try:\n",
        "            detectedObjects = []\n",
        "\n",
        "            for idx in indices:\n",
        "                idxTuple = (idx[0], idx[2])\n",
        "                temp = [i for i in boxes[idxTuple]]  # temp[1, 0, 3, 2] = xmin, ymin, xmax, ymax\n",
        "                dobj = {\n",
        "                    \"type\" : \"entity\",\n",
        "                    \"entity\" : {\n",
        "                        \"tag\" : {\n",
        "                            \"value\" : self._labelList[idx[1]],\n",
        "                            \"confidence\" : str(scores[tuple(idx)])\n",
        "                        },\n",
        "                        \"box\" : {\n",
        "                            \"l\" : str(temp[1] / 416),\n",
        "                            \"t\" : str(temp[0] / 416),\n",
        "                            \"w\" : str((temp[3] - temp[1]) / 416),\n",
        "                            \"h\" : str((temp[2] - temp[0]) / 416)\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "                detectedObjects.append(dobj)\n",
        "\n",
        "            return detectedObjects\n",
        "            \n",
        "        except:\n",
        "            PrintGetExceptionDetails()\n",
        "\n",
        "    def Score(self, cvImage):\n",
        "        try:\n",
        "            with self._lock:\n",
        "                imageBlob = self.Preprocess(cvImage)\n",
        "                boxes, scores, indices = self._onnxSession.run(None, {\"input_1\": imageBlob, \"image_shape\":np.array([[416, 416]], dtype=np.float32)})\n",
        "        \n",
        "            return self.Postprocess(boxes, scores, indices)\n",
        "\n",
        "        except:\n",
        "            PrintGetExceptionDetails()\n",
        "\n",
        "    def About(self):\n",
        "        return str(\"<H1>ONNX Version: \" + onnxruntime.__version__ + \"</H1><BR><H1> App version: v 1.0</H1>\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `score` method of the inference engine class above will return a dictionary of inferences in the following form:\n",
        "\n",
        "```\n",
        "        {\n",
        "            \"entity\": {\n",
        "                \"box\": {\n",
        "                    \"h\": 0.3498992351271351,\n",
        "                    \"l\": 0.027884870008988812,\n",
        "                    \"t\": 0.6497463818662655,\n",
        "                    \"w\": 0.212033897746693\n",
        "                },\n",
        "                \"tag\": {\n",
        "                    \"confidence\": 0.9857677221298218,\n",
        "                    \"value\": \"person\"\n",
        "                }\n",
        "            },\n",
        "            \"type\": \"entity\"\n",
        "        },\n",
        "        {\n",
        "            \"entity\": {\n",
        "                \"box\": {\n",
        "                    \"h\": 0.3593513820482337,\n",
        "                    \"l\": 0.6868949751420454,\n",
        "                    \"t\": 0.6334065123374417,\n",
        "                    \"w\": 0.26539528586647726\n",
        "                },\n",
        "                \"tag\": {\n",
        "                    \"confidence\": 0.9851594567298889,\n",
        "                    \"value\": \"person\"\n",
        "                }\n",
        "            },\n",
        "            \"type\": \"entity\"\n",
        "        }\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "If all the code cells above have successfully finished running, return to the Readme page to continue.   "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}