{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Tensorflow 2 with MultiWorkerMirroredStrategy\n",
    "In this tutorial, you will train a PyTorch model on the [CIFAR10](http://www.cs.toronto.edu/~kriz/cifar.html) dataset using distributed training with Tensorflow 2 `MultiWorkerMirroredStrategy` module across a Azure Stack Hub CPU Kubernetes cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, go through the [AZML-SDK-INSTALL](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/install?view=azure-ml-py)  to install the Azure Machine Learning Python SDK and create an Azure ML `Workspace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1606750503644
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Dataset, Environment, Experiment, Workspace\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "import os\n",
    "import requests\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Initialize workspace\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`. \n",
    "\n",
    "If you haven't done already please go to `config.json` file and fill in your workspace information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1606750507604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Prepare dataset\n",
    "\n",
    "Here we download cifar10 dataset from [cifar10-data](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz). The downloaded data is then registered as dataset in a data store of the workspace. \n",
    "\n",
    "To set up datastore using an azure stack hub storage account, please refer to [Train_azure_arc](https://github.com/penorouzi/AML-Kubernetes/blob/master/docs/ASH/Train-AzureArc.md#create-and-configure-azure-stack-hubs-storage-account). \n",
    "\n",
    "To register the dataset manually, please refer to this [video](https://msit.microsoftstream.com/video/51f7a3ff-0400-b9eb-2703-f1eb38bc6232)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1606064437587
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import requests\n",
    "from azureml.core import Dataset\n",
    "\n",
    "from azureml.exceptions import UserErrorException\n",
    "dataset_name = 'CIFAR-10'\n",
    "try:\n",
    "    ds = Dataset.get_by_name(ws, name=dataset_name)\n",
    "except UserErrorException as e:#dataset not registered\n",
    "\n",
    "    path = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        os.makedirs(os.path.join(tmpdir, 'cifar-10'))\n",
    "\n",
    "        data = requests.get(path, allow_redirects=True).content\n",
    "        with open(os.path.join(tmpdir, 'cifar-10', path.split('/')[-1]), 'wb') as f:\n",
    "            f.write(data)\n",
    "    \n",
    "        datastore_name = \"<my_data_store>\"\n",
    "        ds = Dataset.File.upload_directory(tmpdir, ws.datastores.get(datastore_name), overwrite=True)\n",
    "        ds.register(ws, dataset_name, 'CIFAR-10 images from https://www.cs.toronto.edu/~kriz/cifar.html')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Create or attach existing ArcKubernetesCompute\n",
    "\n",
    "You will need to create a [compute target and attach it to AML](https://github.com/penorouzi/AML-Kubernetes/blob/master/docs/ASH/AML-ARC-Compute.md) for training your model. In this tutorial, ArcKubernetesCompute  ArcKubernetesCompute for our remote training compute resource. Make sure azureml-contrib is installed by following [Private Preview branch of AzureML SDK](https://github.com/penorouzi/AML-Kubernetes/blob/master/docs/ASH/AML-ARC-Compute.md#python-sdk-recommended) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1606662223344
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.contrib.core.compute.arckubernetescompute import ArcKubernetesCompute\n",
    "\n",
    "resource_id = \"<resource_id>\"\n",
    "\n",
    "attach_config = ArcKubernetesCompute.attach_configuration(\n",
    "    resource_id = resource_id\n",
    ")\n",
    "\n",
    "try:\n",
    "    attach_name = \"arc_attach\"\n",
    "    arcK_target = ArcKubernetesCompute.attach(ws, attach_name, attach_config)\n",
    "    arcK_target.wait_for_completion(show_output=True)\n",
    "    print('arc attach  success')\n",
    "except ComputeTargetException as e:\n",
    "    print(e)\n",
    "    print('arc attach  failed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Configure the training job and Submit a run\n",
    " \n",
    " Use TensorflowConfiguration to set number of worker and number of parameter server to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1606750522680
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig, Run\n",
    "from azureml.core.runconfig import TensorflowConfiguration\n",
    "\n",
    "compute_target = ws.compute_targets[attach_name]\n",
    "\n",
    "env = Environment.from_dockerfile(\n",
    "    name='tf_2.4',\n",
    "    dockerfile='./env/Dockerfile.gpu',\n",
    "    conda_specification='./env/tf-24-env.yaml')\n",
    "\n",
    "experiment_name = 'dist-tf2-on-aks-arc'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "worker_count= 1\n",
    "src = ScriptRunConfig(source_directory='./scripts',\n",
    "                      script='train.py',\n",
    "                      arguments=[\n",
    "                          '--dataset-path', ws.datasets[dataset_name].as_mount(),\n",
    "                          '--epochs', 1,#80\n",
    "                          '--global-batch-size', 256,\n",
    "                          '--batches-per-epoch', 256,\n",
    "                          '--alpha-init', 0.005,\n",
    "                      ],\n",
    "                      compute_target=compute_target,\n",
    "                      environment=env,\n",
    "                      distributed_job_config=TensorflowConfiguration(worker_count=worker_count, parameter_server_count=1))#configuring AML TF config\n",
    "\n",
    "rs_config = src.run_config.amlk8scompute.resource_configuration\n",
    "rs_config.gpu_count = 0\n",
    "rs_config.cpu_count = worker_count - rs_config.gpu_count\n",
    "rs_config.memory_request_in_gb = 6\n",
    "\n",
    "run = experiment.submit(config=src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True) # this provides a verbose log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  the model is saved at path \"outputs/001\"\n",
    "# register the model\n",
    "model = run.register_model(model_name='cifar10tf', model_path='outputs/001')"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
